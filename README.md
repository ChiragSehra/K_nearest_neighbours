# K_nearest_neighbours
K-Nearest Neighbours is one of the most basic yet essential classification algorithms in Machine Learning. It belongs to the supervised learning domain and finds intense application in pattern recognition, data mining and intrusion detection.

It is widely disposable in real-life scenarios since it is non-parametric, meaning, it does not make any underlying assumptions about the distribution of data (as opposed to other algorithms such as GMM, which assume a Gaussian distribution of the given data).

We are given some prior data (also called training data), which classifies coordinates into groups identified by an attribute.

As an example, consider the following table of data points containing two features:

![k-nearest-neighbours1](https://user-images.githubusercontent.com/19835029/27906524-85cac24a-6261-11e7-858a-5cc232b1a68a.png)

Now, given another set of data points (also called testing data), allocate these points a group by analyzing the training set. Note that the unclassified points are marked as ‘yellow’.
![k-nearest-neighbours2](https://user-images.githubusercontent.com/19835029/27906540-99b4abe0-6261-11e7-8041-b0de9ca3c049.png)
